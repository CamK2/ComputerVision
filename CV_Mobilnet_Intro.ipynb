{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CamK2/ComputerVision/blob/main/CV_Mobilnet_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning for Object Identification\n",
        "\n",
        "In this lab, we download and run a recent deeplearning model for computer vision that is optimized for minimal resources. In should be able to identify many common objects in everyday life.\n",
        "\n",
        "The fundamental objective of this lab is to:\n",
        "* under stand the big picture process of model training and the landscape of sharing models\n",
        "* become familiar with obtaining and using a recent public deeplearning model\n",
        "* understand some of the limitations of these models (especially minimal models optimized to run on limited hardware)."
      ],
      "metadata": {
        "id": "loeCwxcbHuMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning - the process of training one network on a large broad dataset, then using this generic model along with additional specialized input to continue training to obtain a more specialized network.\n",
        "Examples: AlexNet (old convolutional network) and MobilNet (optimized for small model size)\n",
        "\n",
        "Imagenet - "
      ],
      "metadata": {
        "id": "ENaFdmGCYl5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "There are many deep learning models available for general object identification. However, as we ultimately want this model to run in colab as well as mobile computer hardware, it is crucial that the algorithm run without the enormous computational requirements typical of many models.  \n",
        "\n",
        "We specifically use Google's [*MobileNets*](https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html) family of computer vision models for tensorflow offered a reasonable balace between algorithm performance and hardware requirements.  \n",
        "\n",
        "Google's MobileNetV2 is a neural-network-based **pretrained** model. MobileNetV2 was also designed to have a much smaller parameter count than typical computer vision models. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L5bo7UCs1TbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use Google's *tensorflow* open source software library for deeplearning."
      ],
      "metadata": {
        "id": "fSnOw21GFHbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we install the tensorflow models into the colab environment  \n",
        "!git clone https://github.com/tensorflow/models\n",
        "\n"
      ],
      "metadata": {
        "id": "Hhgp6_Td0dmZ",
        "outputId": "13facc26-622c-4572-b607-ac2963699c5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 77758, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 77758 (delta 70), reused 114 (delta 62), pack-reused 77621\u001b[K\n",
            "Receiving objects: 100% (77758/77758), 593.38 MiB | 26.35 MiB/s, done.\n",
            "Resolving deltas: 100% (55246/55246), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we download the mobilenet 2 model\n",
        "from __future__ import print_function\n",
        "from IPython import display \n",
        "base_name = checkpoint_name = 'mobilenet_v2_1.0_224' #@param\n",
        "url = 'https://storage.googleapis.com/mobilenet_v2/checkpoints/' + checkpoint_name + '.tgz'\n",
        "print('Downloading from ', url)\n",
        "!wget {url}\n",
        "print('Unpacking')\n",
        "!tar -xvf {checkpoint_name}.tgz\n",
        "checkpoint = checkpoint_name + '.ckpt'\n",
        "\n",
        "display.clear_output()\n",
        "print('Successfully downloaded checkpoint from ', url,\n",
        "      '. It is available as', checkpoint)\n"
      ],
      "metadata": {
        "id": "vcy9qBznE-jg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06443b75-e00f-4001-a202-3e8273b30c00"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded checkpoint from  https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz . It is available as mobilenet_v2_1.0_224.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we install tf_slim, a lightweight library for  \n",
        "# evaluating models in TensorFlow\n",
        "import sys\n",
        "sys.path.append('/content/models/research/slim')\n",
        "!pip install tf_slim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSFRv6j5ISFe",
        "outputId": "c8109b5a-041c-4c37-f55f-5a2ec847f296"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf_slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (1.2.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG -O panda.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fON2yg7mKdVc",
        "outputId": "ce46d0d3-67b4-40d4-9122-7d771243d492"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-07 17:17:55--  https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240, 2620:0:861:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116068 (113K) [image/jpeg]\n",
            "Saving to: ‘panda.jpg’\n",
            "\n",
            "\rpanda.jpg             0%[                    ]       0  --.-KB/s               \rpanda.jpg           100%[===================>] 113.35K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-10-07 17:17:56 (3.67 MB/s) - ‘panda.jpg’ saved [116068/116068]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the trained model into tensorflow\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tf_slim as slim\n",
        "from nets.mobilenet import mobilenet_v2\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# For simplicity we just decode jpeg inside tensorflow.\n",
        "# But one can provide any input obviously.\n",
        "file_input = tf.placeholder(tf.string, ())\n",
        "\n",
        "image = tf.image.decode_jpeg(tf.read_file(file_input))\n",
        "\n",
        "images = tf.expand_dims(image, 0)\n",
        "images = tf.cast(images, tf.float32) / 128.  - 1\n",
        "images.set_shape((None, None, None, 3))\n",
        "images = tf.image.resize_images(images, (224, 224))\n",
        "\n",
        "# Note: arg_scope is optional for inference.\n",
        "with slim.arg_scope(mobilenet_v2.training_scope(is_training=False)):\n",
        "  logits, endpoints = mobilenet_v2.mobilenet(images)\n",
        "  \n",
        "# Restore using exponential moving average since it produces (1.5-2%) higher \n",
        "# accuracy\n",
        "ema = tf.train.ExponentialMovingAverage(0.999)\n",
        "vars = ema.variables_to_restore()\n",
        "\n",
        "saver = tf.train.Saver(vars)  "
      ],
      "metadata": {
        "id": "mM_fcvUHJjyV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Images\n",
        "Here we demonstrate processing of images to generate text labels for the target candidates."
      ],
      "metadata": {
        "id": "rQzQs2gfGpP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The wget command downloads images from the internet.\n",
        "!wget \"https://robbreport.com/wp-content/uploads/2022/01/Cielo2.jpg\"\n",
        "!wget 'https://www.defensenews.com/resizer/U2oS79JL6Z7cX9bXU9zUMBI9bJk=/1024x0/filters:format(jpg):quality(70)/cloudfront-us-east-1.images.arcpublishing.com/archetype/OIFRAG2XKFDPPKI5KVUURA5474' -O sideTank.jpg.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfbS53zVGnbI",
        "outputId": "33eba957-6b89-46f3-b5ac-37e1944895ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-07 17:21:52--  https://robbreport.com/wp-content/uploads/2022/01/Cielo2.jpg\n",
            "Resolving robbreport.com (robbreport.com)... 192.0.66.24\n",
            "Connecting to robbreport.com (robbreport.com)|192.0.66.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 880729 (860K) [image/jpeg]\n",
            "Saving to: ‘Cielo2.jpg’\n",
            "\n",
            "\rCielo2.jpg            0%[                    ]       0  --.-KB/s               \rCielo2.jpg          100%[===================>] 860.09K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-10-07 17:21:52 (12.5 MB/s) - ‘Cielo2.jpg’ saved [880729/880729]\n",
            "\n",
            "--2022-10-07 17:21:53--  https://www.defensenews.com/resizer/U2oS79JL6Z7cX9bXU9zUMBI9bJk=/1024x0/filters:format(jpg):quality(70)/cloudfront-us-east-1.images.arcpublishing.com/archetype/OIFRAG2XKFDPPKI5KVUURA5474\n",
            "Resolving www.defensenews.com (www.defensenews.com)... 23.213.26.137, 23.213.26.147, 2600:1408:5400:17::17dd:e3a9, ...\n",
            "Connecting to www.defensenews.com (www.defensenews.com)|23.213.26.137|:443... connected.\n",
            "HTTP request sent, awaiting response... 403 Forbidden\n",
            "2022-10-07 17:21:53 ERROR 403: Forbidden.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://www.defensenews.com/resizer/U2oS79JL6Z7cX9bXU9zUMBI9bJk=/1024x0/filters:format(jpg):quality(70)/cloudfront-us-east-1.images.arcpublishing.com/archetype/OIFRAG2XKFDPPKI5KVUURA5474.jpg' width=300>"
      ],
      "metadata": {
        "id": "iXrvy3stH_l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "import pylab\n",
        "from datasets import imagenet\n",
        "import PIL\n",
        "#display.display(display.Image('sideTank.jpg'))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  saver.restore(sess,  checkpoint)\n",
        "  x = endpoints['Predictions'].eval(feed_dict={file_input: 'Cielo2.jpg'})\n",
        "label_map = imagenet.create_readable_names_for_imagenet_labels()  \n",
        "print(\"Top 1 prediction: \", x.argmax(),label_map[x.argmax()], x.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TOKqcZxH18X",
        "outputId": "4a74427d-c262-414c-f6d5-6d487e047de3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 prediction:  484 castle 0.6609741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add image where it fails"
      ],
      "metadata": {
        "id": "3dvkmZTYMFdD"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}