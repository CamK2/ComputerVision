{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CamK2/ComputerVision/blob/main/CNN_Fashion_MNIST_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjmUDGHLWpbz"
      },
      "source": [
        "## What is this?\n",
        "\n",
        "This Jupyter Notebook contains Python code for building a Convolutional Neural Network that gives 90% accuracy on classification of the Fashion MNIST Dataset. More information is given on [this blogpost](https://www.bouvet.no/bouvet-deler/understanding-convolutional-neural-networks-part-2).\n",
        "\n",
        "This code is supplied without license, warranty or support. Feel free to do with it what you will."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D86_YqBol8e"
      },
      "source": [
        "## Built for Google Collaboratory ##\n",
        "\n",
        "Train your network more quickly in Google Collaboratory. From the **Runtime** menu select **Change Runtime Type** and choose \"GPU\"!\n",
        "\n",
        "Don't forget to select **Runtime** -> **Restart runtime** to put your changes into effect!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSRFTqbOYAUY"
      },
      "source": [
        "## Setting up\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HNLKc5fX9Nw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a35bff-4530-4473-8e73-9d77f34f3410"
      },
      "source": [
        "# All the imports!\n",
        "import tensorflow as tf # tested with 1.14.0\n",
        "import numpy as np # tested with 1.16.4\n",
        "import matplotlib.pyplot as plt #tested with 3.0.3\n",
        "from sklearn.metrics import classification_report # tested with 0.21.2l\n",
        "\n",
        "# Supress deprecation warnings\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True\n",
        "\n",
        "# Fetch \"Fashion MNIST\" data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# A good rule of thumb is to normalise input values - i.e. transform them to a\n",
        "# scale of 0 to 1. Each element in this dataset is a pixel value of 0 to 255, so\n",
        "# we'll normalise / rescale these values.\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Map for human readable class names\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcMYWwb9YjMe"
      },
      "source": [
        "## Get data shapes\n",
        "\n",
        "We are expecting 60000 training images and 10000 test images, where each image is comprised of 28x28 greyscale pixel values. \n",
        "\n",
        "In addition we have the classes to which each image belongs. These are held in seperate files.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svbfCKBOYp-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae76dcd-4fe0-439d-888a-dbdc69611118"
      },
      "source": [
        "print(\"Shape of Training Image Data: \" + str(x_train.shape))\n",
        "print(\"Shape of Training Class Data: \" + str(y_train.shape))\n",
        "print(\"Shape of Test Image Data: \" + str(x_test.shape))\n",
        "print(\"Shape of Test Class Data: \" + str(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Training Image Data: (60000, 28, 28)\n",
            "Shape of Training Class Data: (60000,)\n",
            "Shape of Test Image Data: (10000, 28, 28)\n",
            "Shape of Test Class Data: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnPYVK-1Y6Pk"
      },
      "source": [
        "## Visualise first 25 images from training data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym0c8NpnY50k"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iontg782ZeH5"
      },
      "source": [
        "## Visualise image with pixel values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9KfNXIuZp0Y"
      },
      "source": [
        "# Lets view the first image and classname in the dataset \n",
        "# Tip: Change \"index\" value to view different images.\n",
        "index = 0\n",
        "plt.figure(figsize=(20,16))\n",
        "plt.imshow(x_train[index], cmap=plt.cm.binary)\n",
        "plt.xlabel(class_names[y_train[index]])\n",
        "plt.colorbar()\n",
        "#plt.grid(True)\n",
        "#plt.rc('grid', linestyle=\"-\", color='fuchsia')\n",
        "\n",
        "ax = plt.gca()\n",
        "ax.set_xticks(np.arange(-.5, 28, 1))\n",
        "ax.set_yticks(np.arange(-.5, 28, 1))\n",
        "ax.set_xticklabels(np.arange(0, 29, 1))\n",
        "ax.set_yticklabels(np.arange(0, 29, 1))\n",
        "ax.xaxis.tick_top()\n",
        "\n",
        "# Adds Pixel Values on top of image\n",
        "#for i in range(28):\n",
        "#    for j in range(28):\n",
        "#        text = ax.text(j, i, round(x_train[index][i, j], 2),\n",
        "#                       ha=\"center\", va=\"center\", color=\"fuchsia\")\n",
        "        \n",
        "        \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrT53xeSbDHe"
      },
      "source": [
        "## Create and build Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_RzUtykbIbr"
      },
      "source": [
        "# We begin by defining the a empty stack. We'll use this for building our \n",
        "# network, later by layer.\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# We start with a convolutional layer this will extract features from \n",
        "# the input images by sliding a convolution filter over the input image, \n",
        "# resulting in a feature map.\n",
        "model.add(\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=32, # How many filters we will learn \n",
        "        kernel_size=(3, 3), # Size of feature map that will slide over image\n",
        "        strides=(1, 1), # How the feature map \"steps\" across the image\n",
        "        padding='valid', # We are not using padding\n",
        "        activation='relu', # Rectified Linear Unit Activation Function\n",
        "        input_shape=(28, 28, 1) # The expected input shape for this layer\n",
        "    )\n",
        ") \n",
        "\n",
        "# The next layer we will add is a Maxpooling layer. This will reduce the \n",
        "# dimensionality of each feature, which reduces the number of parameters that \n",
        "# the model needs to learn, which shortens training time.\n",
        "model.add(\n",
        "    tf.keras.layers.MaxPooling2D(\n",
        "        pool_size=(2, 2), # Size feature will be mapped to\n",
        "        strides=(2, 2) # How the pool \"steps\" across the feature\n",
        "    )\n",
        ")\n",
        "          \n",
        "# We'll now add a dropout layer. This fights overfitting and forces the model to \n",
        "# learn multiple representations of the same data by randomly disabling neurons \n",
        "# in the learning phase.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "# Output from previous layer is a 3D tensor. This must be flattened to a 1D \n",
        "# vector before beiung fed to the Dense Layers.\n",
        "model.add(\n",
        "    tf.keras.layers.Flatten()\n",
        ")\n",
        "\n",
        "# A dense (interconnected) layer is added for mapping the derived features \n",
        "# to the required class.\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=128, # Output shape\n",
        "        activation='relu' # Rectified Linear Unit Activation Function\n",
        "    )\n",
        ")\n",
        "\n",
        "# Final layer with 10 outputs and a softmax activation. Softmax activation \n",
        "# enables me to calculate the output based on the probabilities. \n",
        "# Each class is assigned a probability and the class with the maximum \n",
        "# probability is the model’s output for the input.\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=10, # Output shape\n",
        "        activation='softmax' # Softmax Activation Function\n",
        "    )\n",
        ")\n",
        "\n",
        "# Build the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy, # loss function\n",
        "    optimizer=tf.keras.optimizers.Adam(), # optimizer function\n",
        "    metrics=['accuracy'] # reporting metric\n",
        ")\n",
        "\n",
        "# Display a summary of the models structure\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIbCDVxXQ10C"
      },
      "source": [
        "## Visualise the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIF9upctQyy3"
      },
      "source": [
        "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZpd_vWLcfU9"
      },
      "source": [
        "## Train the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNWdTFc3cilQ"
      },
      "source": [
        "# Add an empty color dimension as the Convolutional net is expecting this\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "# Train the CNN on the training data\n",
        "history = model.fit(\n",
        "    \n",
        "      # Training data : features (images) and classes.\n",
        "      x_train, y_train,\n",
        "                    \n",
        "      # number of samples to work through before updating the \n",
        "      # internal model parameters via back propagation.\n",
        "      batch_size=256, \n",
        "\n",
        "      # An epoch is an iteration over the entire training data.\n",
        "      epochs=10, \n",
        "\n",
        "      # The model will set apart his fraction of the training \n",
        "      # data, will not train on it, and will evaluate the loss\n",
        "      # and any model metrics on this data at the end of \n",
        "      # each epoch. \n",
        "      validation_split=0.2, \n",
        "\n",
        "      verbose=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7FI8OgXe00J"
      },
      "source": [
        "## Evaluate model with test data and view results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYRQQIKhexMe"
      },
      "source": [
        "# Get Model Predictions for test data\n",
        "p_val = model.predict(x_test)\n",
        "predicted_classes = np.argmax(p_val, axis=1)\n",
        "print(classification_report(y_test, predicted_classes, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5ISTseAhkm3"
      },
      "source": [
        "## View examples of incorrectly classified test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFXEvBB9hvor"
      },
      "source": [
        "incorrect = np.nonzero(predicted_classes!=y_test)[0]\n",
        "\n",
        "# Display the first 16 incorrectly classified images from the test data set\n",
        "plt.figure(figsize=(15, 8))\n",
        "for j, incorrect in enumerate(incorrect[0:8]):\n",
        "    plt.subplot(2, 4, j+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_test[incorrect].reshape(28, 28), cmap=\"Reds\")\n",
        "    plt.title(\"Predicted: {}\".format(class_names[predicted_classes[incorrect]]))\n",
        "    plt.xlabel(\"Actual: {}\".format(class_names[y_test[incorrect]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FNWsc2wp1-e"
      },
      "source": [
        "## Print Feature Maps from the Convolutional Layer\n",
        "\n",
        "Inspired by this blogpost: https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0.\n",
        "\n",
        "Basically what we do here is to copy a slice of our trained model - the Conv2D Layer. We then feed in a test image and visualise the output from the Conv2D - our feature maps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwyLfivClrRJ"
      },
      "source": [
        "# The layer we want to copy from the trained CNN\n",
        "layer_name = 'conv2d' \n",
        "\n",
        "# Get the list of layers for the existing model\n",
        "layer_dict = {layer.name : layer for layer in model.layers}\n",
        "\n",
        "# Create a copy of our existing model containing just the Conv2D Layer\n",
        "modelslice = tf.keras.Model(inputs=model.inputs, outputs=layer_dict[layer_name].output)\n",
        "\n",
        "# Choose an image (0 to 59999) from the training set\n",
        "image = x_train[0] \n",
        "\n",
        "# Add the extra dimension expected by the slice\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Send the image through the model\n",
        "feature_maps = modelslice.predict(image)\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "    \n",
        "# We are assuming that we have 32 feature maps\n",
        "for i in range(32):\n",
        "    plt.subplot(4,8,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(feature_maps[0, :, :, i-1], cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}